---
description: How to research where supply meets demand... üí∞üßë‚Äçüè´
---

# What data is valuable?

<figure><img src="../.gitbook/assets/big-money.gif" alt=""><figcaption></figcaption></figure>

### Simple Truths

A lot of people miss the mark on tokenizing data that actually _sells_. If your goal is to make money, then you have to research target audiences, who's currently buying data, and \*correctly price\* your data to meet that demand.

To figure out which market segments are paying for data, then it may help you to **go to the Ocean Market and sort by Sales.**

But even then, it's not enough to just publish useful data on Ocean. **You need to market your data** **assets** to close sales.&#x20;

Have you tried all these things and are still having trouble making money? Never fear! You can enter one of our [data challenges](https://oceanprotocol.com/challenges) to make sweet OCEAN rewards and build your data science skills.

But what if you're a well-heeled company looking to create dApps or source data predictions? You can kickstart the value creation loop by working with Ocean Protocol to [sponsor a data challenge](data-challenges/hosting-a-data-challenge.md).

### Brainstorming Useful Data to Upload

Below is a short list of potential areas to curate useful data.

* **Government Open Data:** Governments serve as a rich and reliable source of data. However, this data often lacks proper documentation or poses challenges for data scientists to work with effectively. Establishing robust Extract, Transform, Load (ETL) pipelines enhance accessibility to government open data. This way, others can tap into this wealth of information without unnecessary hurdles. For example, in one of our [data challenges](https://desights.ai/shared/challenge/8) we leveraged public real estate data from Dubai to build use cases for understanding and predicting valuations and rents. Local, state, and federal governments around the world provide access to valuable data. Build pipelines to make consuming that data easier and help others build useful products to help your local community.
* **Public APIs:** A wide range of freely available public APIs covers various data verticals. Leveraging these APIs, data engineers can construct pipelines that enable efficient access and utilization of the data. [This ](https://github.com/public-apis/public-apis)is a repository of public APIs for a wide range of topics, from weather to gaming to finance.
* **On-Chain Data:** Blockchain data presents a unique opportunity for data engineers to curate high-quality data. There is consistent demand for well-curated decentralized finance (DeFi) data and an emerging need for curated data in other domains, such as decentralized social data. Build datasets for a range of use cases such as trading to customer analytics
* **Datasets for training foundation models:** Build pipelines for training foundation models. Conduct web scraping and aggregate existing commercially licensed datasets
* **Datasets for fine-tuning foundation models:** Curate high-quality labeled datasets to fine-tune foundation models. label the outputs of models or create&#x20;
